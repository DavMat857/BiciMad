{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La empresa gestora de BiciMad se encuentra ante un problema que busca resolver a través de un estudio centrado en las edades y el tiempo promedio de viaje de sus usuarios. El propósito de este estudio es doble: por un lado, utilizar estos datos como criterios para su expansión a nuevas zonas y, por otro lado, establecer una promoción especial que ofrece un descuento a los usuarios.\n",
    "\n",
    "Para activar esta promoción, se ha decidido establecer un requisito específico: los usuarios deberán alcanzar un tiempo medio de uso determinado. De esta manera, se busca no solo incentivar un mayor uso de BiciMad, sino también promover el disfrute de los servicios que la empresa ofrece.\n",
    "\n",
    "Este análisis de las edades y los tiempos promedio de viaje proporcionará a BiciMad información valiosa para la toma de decisiones estratégicas. Con estos datos, la empresa podrá identificar áreas con una demanda más significativa, optimizar su expansión y, en última instancia, brindar un servicio más completo y adaptado a las necesidades de sus usuarios.\n",
    "\n",
    "#### Para ello usaremos el siguiente script\n",
    "\n",
    "`conteo_rango_edades.py`: lee una serie de base de datos en las que se encuentre información relacionada con ageRange, y se realiza un diagrama de los sectores, además calcula el tiempo medio de viaje.\n",
    "\n",
    "En primer lugar, el scipt guarda la dirección de las bases de datos que se le pasen cómo parámetros de entrada (ruta concatenado con el nombre de las bases de datos).\n",
    " Seguidamente, se crea un RDD vacío al cual se van a ir añadiendo el contenido extraido de las lecturas de la base de datos usando los métodos perezosos 'map', 'filter' y 'union'. Se ha filtrado el tiempo de uso a mas de 1 minuto, para evitar tomar posibles datos erróneos. Así, después de leer todos los archivos, tendríamos un RDD de pares (ageRange, travel_time).\n",
    " Para seguir con el estudio, se selecciona la primera componente de este último RDD, contamos las veces que se repite un valor mediante el método 'countByValue', se convierte a diccionario ordenando por orden creciente las claves (valores que van del 0 al 6) para seguidamente llamar a la funcion 'gráfica_queso' que creará el grafico de sectores con los datos de las bases de datos y, por defecto, guardará el resultado en la carpeta 'resultados'.\n",
    " Una vez tenemos los gráficos, el calculo del tiempo medio de uso es parecido: mediante el método 'sum', sumamos todos los 'travel_time' y para obtener la cantidad de viajes se suman los valores asociados a cada clave en el diccionario usado para crear los gráficos. Con esto, calculamos la media y, por defecto, nos quedamos con 3 decimales del resultado.\n",
    " \n",
    " \n",
    " __Observación__: para este análisis se han realizados dos caso:\n",
    " \n",
    " <ol>\n",
    " <li> Sin filtrado de datos: tomando directamente los datos </li>\n",
    " <li> Filtrando datos que consideramos poco importantes: una limpieza de datos, que se resume en eliminar los usuarios con edad no registrado </li>\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/28 13:09:24 WARN Utils: Your hostname, ubuntu22 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/05/28 13:09:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/28 13:09:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/28 13:09:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/05/28 13:09:30 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/Escritorio/BiciMad/scripts/conteo_rango_edades.py\", line 104, in <module>\n",
      "    main2(sc, lst)\n",
      "  File \"/home/david/Escritorio/BiciMad/scripts/conteo_rango_edades.py\", line 62, in main2\n",
      "    rdd_contenido = rdd_contenido.union(contenido_filtrado_2_rdd) #unimos los rdd`s para tener 1 único rdd de pares\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/pyspark/rdd.py\", line 1253, in union\n",
      "    rdd = RDD(self_copy._jrdd.union(other_copy._jrdd), self.ctx, self.ctx.serializer)\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/david/.local/lib/python3.10/site-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o32.union.\n",
      ": org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/home/david/Escritorio/BiciMad/datos/movements/DatosDeUso_12_2020.json\n",
      "\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:304)\n",
      "\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:244)\n",
      "\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:332)\n",
      "\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\n",
      "\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:55)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$union$2(SparkContext.scala:1428)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$union$2$adapted(SparkContext.scala:1428)\n",
      "\tat scala.collection.TraversableLike.noneIn$1(TraversableLike.scala:319)\n",
      "\tat scala.collection.TraversableLike.filterImpl(TraversableLike.scala:385)\n",
      "\tat scala.collection.TraversableLike.filterImpl$(TraversableLike.scala:297)\n",
      "\tat scala.collection.AbstractTraversable.filterImpl(Traversable.scala:108)\n",
      "\tat scala.collection.TraversableLike.filter(TraversableLike.scala:395)\n",
      "\tat scala.collection.TraversableLike.filter$(TraversableLike.scala:395)\n",
      "\tat scala.collection.AbstractTraversable.filter(Traversable.scala:108)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$union$1(SparkContext.scala:1428)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.SparkContext.withScope(SparkContext.scala:810)\n",
      "\tat org.apache.spark.SparkContext.union(SparkContext.scala:1427)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$union$5(SparkContext.scala:1439)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.SparkContext.withScope(SparkContext.scala:810)\n",
      "\tat org.apache.spark.SparkContext.union(SparkContext.scala:1439)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$union$1(RDD.scala:655)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\n",
      "\tat org.apache.spark.rdd.RDD.union(RDD.scala:655)\n",
      "\tat org.apache.spark.api.java.JavaRDD.union(JavaRDD.scala:177)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Input path does not exist: file:/home/david/Escritorio/BiciMad/datos/movements/DatosDeUso_12_2020.json\n",
      "\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:278)\n",
      "\t... 51 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/conteo_rango_edades.py \"datos/movements\" \"DatosDeUso_12_2020.json\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a abrir dos imágenes una con un filtrado de datos y otro sin él"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'comparacion_rango_edades.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpimg\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Cargar las imágenes\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m imagen1 \u001b[39m=\u001b[39m mpimg\u001b[39m.\u001b[39;49mimread(\u001b[39m'\u001b[39;49m\u001b[39mcomparacion_rango_edades.png\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m imagen2 \u001b[39m=\u001b[39m mpimg\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mcomparacion_rango_edades_filtrado.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Crear una figura y agregar subplots\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\image.py:1563\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(parse\u001b[39m.\u001b[39murlparse(fname)\u001b[39m.\u001b[39mscheme) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1557\u001b[0m     \u001b[39m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1559\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease open the URL for reading and pass the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresult to Pillow, e.g. with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1561\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m         )\n\u001b[1;32m-> 1563\u001b[0m \u001b[39mwith\u001b[39;00m img_open(fname) \u001b[39mas\u001b[39;00m image:\n\u001b[0;32m   1564\u001b[0m     \u001b[39mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1565\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image, PIL\u001b[39m.\u001b[39mPngImagePlugin\u001b[39m.\u001b[39mPngImageFile) \u001b[39melse\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\PIL\\ImageFile.py:105\u001b[0m, in \u001b[0;36mImageFile.__init__\u001b[1;34m(self, fp, filename)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecodermaxblock \u001b[39m=\u001b[39m MAXBLOCK\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m is_path(fp):\n\u001b[0;32m    104\u001b[0m     \u001b[39m# filename\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(fp, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m fp\n\u001b[0;32m    107\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'comparacion_rango_edades.png'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Cargar las imágenes\n",
    "imagen1 = mpimg.imread('comparacion_rango_edades.png')\n",
    "imagen2 = mpimg.imread('comparacion_rango_edades_filtrado.png')\n",
    "\n",
    "# Crear una figura y agregar subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Mostrar las imágenes en los subplots\n",
    "axes[0].imshow(imagen1)\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Sin filtrar datos')\n",
    "\n",
    "axes[1].imshow(imagen2)\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Filtrando datos')\n",
    "\n",
    "# Ajustar la distribución de los subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar la figura con las imágenes\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones:\n",
    "\n",
    "* La mayoría de los usuarios no tienen registrado la edad. Por lo tanto, se sugiere considerar la posibilidad de realizar una promoción o incentivo para obtener más datos sobre los usuarios y poder personalizar las ofertas y servicios.\n",
    "\n",
    "* Observando la imagen proporcionada en la celda anterior, se puede notar que la mayoría de los usuarios registrados se encuentran en los grupos 4 y 5, correspondientes a edades entre 27 y 65 años. Esto indica que BiciMad tiene una buena aceptación en este rango de edad y puede enfocar sus estrategias de marketing y expansión en esta audiencia.\n",
    "\n",
    "* Los grupos 1 y 2, correspondientes a usuarios menores de edad, muestran una baja representación en los registros. Para captar y fidelizar a este grupo de usuarios jóvenes, se sugiere considerar la implementación de viajes gratuitos o bonos especiales que les brinden beneficios exclusivos. Esto ayudaría a generar interés y crear una base de usuarios sólida desde temprana edad."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En relación al tiempo medio de viaje:\n",
    "\n",
    "Tenemos el dato de que el tiempo medio de viaje es 1056.55 segundos, que son 17.61 minutos.\n",
    "\n",
    "Teniendo en cuenta esta información, la empresa ha decidido poner en marcha una estrategia de descuento como incentivo para sus usuarios. La idea es utilizar el tiempo medio de viaje como criterio para determinar qué usuarios podrán acceder a este descuento especial. Aquellos usuarios que cumplan con el tiempo medio establecido serán beneficiados con una reducción en el costo de sus viajes.\n",
    "\n",
    "Esta estrategia de descuento basada en el tiempo medio de viaje tiene múltiples ventajas para la empresa. En primer lugar, fomenta un mayor uso de BiciMad al incentivar a los usuarios a realizar viajes más prolongados. Esto a su vez contribuye a un mayor tiempo de uso de las bicicletas y, potencialmente, a un aumento en los ingresos generados por el servicio.\n",
    "\n",
    "Además, esta estrategia permite recopilar información valiosa sobre los hábitos de uso de los usuarios. Al monitorear el tiempo medio de viaje y analizar los datos resultantes, la empresa puede obtener insights sobre las preferencias de los usuarios, los patrones de movilidad y las áreas de mayor interés. Esta información puede ser utilizada para mejorar la planificación de rutas, optimizar la distribución de estaciones y enfocar los esfuerzos de expansión en las áreas de mayor demanda."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los problemas que enfrenta la empresa gestora de BiciMad es la falta de visibilidad y comprensión sobre las estaciones más concurridas y los trayectos más populares a lo largo del día. Sin esta información, resulta difícil tomar decisiones estratégicas para mejorar la oferta de servicios y optimizar la ubicación de las estaciones en función de la demanda real. Para ello usaremos el script `mapa_dia.py`.\n",
    "\n",
    "Primero, el programa guarda las posiciones ([longitude,latitude]) y los identificadores de las estaciones activas para el día específico que se ha introducido como valor de entrada, y hace lo propio con las variables idplug_station (estación de enganche) e idunplug_station (estación de desenganche) del fichero que guarda los movimientos de los usuarios conectados a la red de Bicimad.\n",
    "\n",
    "Con esta información se evalúa cuáles han sido las estaciones más concurridas a lo largo del día introducido, y utilizando la librería de visualización geoespacial folium presentamos esta información en un mapa de forma que se pueda acceder a la información de enganches y desenganches de todas las estaciones, así como proporcionar una representación que (mediante una escala de color) permita conocer cuáles son las estaciones de mayor interés. Es importante remarcar que el formato de los archivos JSON debe ser el que siguen los archivos del año 2020 (véanse DatosDeUso_12_2020.json y SituacionesEstaciones12_2020.json como posibles referencias) de libre acceso en la página web de la EMT de Madrid https://opendata.emtmadrid.es/Datos-estaticos/Datos-generales.\n",
    "\n",
    "Además, se han delineado los trayectos con más apariciones en el conjunto de datos de uso de los cuáles se ha seleccionado top = 500 para visualizar las 500 rutas más concurridas a lo large de ese día, junto con la información de las estaciones explicada en el párrafo anterior. Si se desea, este valor puede cambiarse dentro del código para reducir o aumentar el número de rutas a considerar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/d:/Documentos/BiciMad-1/DatosDeuso12_2020.json\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:304)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:244)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:332)\r\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:208)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\r\n\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:55)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\r\nCaused by: java.io.IOException: Input path does not exist: file:/d:/Documentos/BiciMad-1/DatosDeuso12_2020.json\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:278)\r\n\t... 34 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m conf \u001b[39m=\u001b[39m SparkConf()\u001b[39m.\u001b[39msetAppName(\u001b[39m\"\u001b[39m\u001b[39mmapaBicimad\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m sc \u001b[39m=\u001b[39m SparkContext(conf\u001b[39m=\u001b[39mconf) \n\u001b[1;32m----> 7\u001b[0m main(sc)\n",
      "File \u001b[1;32md:\\Documentos\\BiciMad-1\\scripts\\mapa_dia.py:67\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(sc, usage_file, stations_file, day, outfile, top)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m# Extraemos la información de los enganches y desenganches\u001b[39;00m\n\u001b[0;32m     65\u001b[0m result \u001b[39m=\u001b[39m filtered_usage_rdd\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: {\u001b[39m'\u001b[39m\u001b[39midplug_station\u001b[39m\u001b[39m'\u001b[39m: json\u001b[39m.\u001b[39mloads(x)[\u001b[39m'\u001b[39m\u001b[39midplug_station\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     66\u001b[0m                                         \u001b[39m'\u001b[39m\u001b[39midunplug_station\u001b[39m\u001b[39m'\u001b[39m: json\u001b[39m.\u001b[39mloads(x)[\u001b[39m'\u001b[39m\u001b[39midunplug_station\u001b[39m\u001b[39m'\u001b[39m]})\n\u001b[1;32m---> 67\u001b[0m result1 \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mcollect()\n\u001b[0;32m     68\u001b[0m trips \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: \u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39mvalues()))\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m     69\u001b[0m trips_count \u001b[39m=\u001b[39m count_occurrences(trips)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\rdd.py:1814\u001b[0m, in \u001b[0;36mRDD.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext):\n\u001b[0;32m   1813\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1814\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonRDD\u001b[39m.\u001b[39;49mcollectAndServe(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jrdd\u001b[39m.\u001b[39;49mrdd())\n\u001b[0;32m   1815\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/d:/Documentos/BiciMad-1/DatosDeuso12_2020.json\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:304)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:244)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:332)\r\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:208)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\r\n\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:55)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:291)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:287)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2328)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1019)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:405)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1018)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\r\nCaused by: java.io.IOException: Input path does not exist: file:/d:/Documentos/BiciMad-1/DatosDeuso12_2020.json\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:278)\r\n\t... 34 more\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from scripts.mapa_dia import main\n",
    "\n",
    "conf = SparkConf().setAppName(\"mapaBicimad\")\n",
    "sc = SparkContext(conf=conf) \n",
    "main(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos el mapa creado\n",
    "import webbrowser\n",
    "\n",
    "file_path = \"mapa_madrid.html\"\n",
    "webbrowser.open(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Solución**:\n",
    "\n",
    "Para abordar este problema, se ha desarrollado un programa que utiliza datos de posicionamiento y movimientos de los usuarios para identificar las estaciones más concurridas y visualizar esta información en un mapa interactivo. La solución se basa en los siguientes pasos:\n",
    "\n",
    "Recopilación de datos: El programa recopila información sobre las posiciones (longitude, latitude) y los identificadores de las estaciones activas para el día específico proporcionado como entrada. Además, se obtienen los datos de las estaciones de enganche y desenganche de los usuarios conectados a la red de BiciMad.\n",
    "\n",
    " Evaluación de las estaciones más concurridas: Utilizando los datos recopilados, se analiza cuáles han sido las estaciones más concurridas a lo largo del día. Esto se realiza teniendo en cuenta tanto las estaciones de enganche como las de desenganche de los usuarios. Esta evaluación proporciona una visión clara de las áreas de mayor interés y demanda en la red de BiciMad.\n",
    "\n",
    "Visualización en un mapa interactivo: Se utiliza la librería de visualización geoespacial folium para presentar la información recopilada en un mapa interactivo. El mapa muestra todas las estaciones y permite acceder a la información de enganches y desenganches de cada una. Además, se utiliza una escala de color para resaltar las estaciones de mayor interés, lo que facilita la identificación visual de las áreas más concurridas.\n",
    "\n",
    "Delineación de trayectos populares: Se seleccionan los trayectos más frecuentes en el conjunto de datos de uso. El programa permite ajustar el parámetro \"top\" para determinar el número de rutas a considerar. Por defecto, se visualizan las 500 rutas más concurridas del día. Esta información complementa la visualización de las estaciones, brindando una comprensión más completa de los patrones de movimiento de los usuarios.\n",
    "\n",
    "Esta solución permite a la empresa gestora de BiciMad obtener una visión clara de las estaciones más concurridas y los trayectos populares, lo que facilita la toma de decisiones estratégicas. Con esta información, la empresa puede optimizar la ubicación de las estaciones, ajustar la oferta de servicios en áreas de mayor demanda y mejorar la experiencia global de los usuarios. Además, la visualización en un mapa interactivo brinda una forma intuitiva de acceder y comprender la información, facilitando la identificación de patrones y tendencias importantes.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texto rutas lentas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from scripts.rutas_lentas import obtener_velocidades\n",
    "\n",
    "# Creamos la sesión de Spark\n",
    "spark_session = SparkSession.builder.appName(\"RutasLentas\").config(\"spark.executor.memory\", \"8g\").getOrCreate()\n",
    "spark_session.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Elegimos el mes que vamos a analizar\n",
    "ruta_movements = r\"datos/movements/202012_movements.json\"\n",
    "ruta_stations = r\"datos/stations/202012_stations.json\"\n",
    "\n",
    "velocidades = obtener_velocidades(ruta_movements, ruta_stations, spark_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+\n",
      "|   ruta|              mean|count|\n",
      "+-------+------------------+-----+\n",
      "| 38-224|4.7609375174648205|   96|\n",
      "|209-213| 4.617594746615498|   67|\n",
      "|  3-226| 4.301327266312668|   53|\n",
      "|113-216| 4.236109768967397|   59|\n",
      "| 79-102| 4.161095596323144|   59|\n",
      "| 79-115| 4.111824250056706|   58|\n",
      "|  83-90| 4.107847274219228|   72|\n",
      "| 33-184| 4.053327895361842|   68|\n",
      "| 26-139|3.9887256064199033|   70|\n",
      "| 13-149| 3.932667720958131|   65|\n",
      "+-------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "velocidades.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "escribir conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 4\n",
    "\n",
    "La movilidad urbana sostenible se ha convertido en una prioridad para las ciudades modernas. En este sentido, BiciMad, ha demostrado ser una solución eficaz y eficiente para abordar los desafíos medioambientales y mejorar la calidad de vida de sus habitantes. A través de la implementación de una infraestructura adecuada y la promoción de su uso, BiciMad ha logrado posicionarse como una alternativa de transporte ecológica y viable en el entorno urbano.\n",
    "\n",
    "Vamos a tratar la cuatificación de la `reducción de emisiones de carbono`:\n",
    "\n",
    "Una de las principales ventajas de BiciMad es su capacidad para reducir las emisiones de carbono asociadas al transporte. Al promover el uso de la bicicleta como medio de transporte alternativo, se disminuye la dependencia de los vehículos motorizados que utilizan combustibles fósiles y emiten grandes cantidades de dióxido de carbono (CO2) a la atmósfera. La bicicleta es un medio de transporte limpio y libre de emisiones, lo que la convierte en una opción sostenible para desplazarse por la ciudad.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trabajaremos con los datos de 2020/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from scripts.contaminación import distancia_recorrida\n",
    "\n",
    "# Creamos la sesión de Spark\n",
    "spark_session = SparkSession.builder.appName(\"distancia_recorrida\").config(\"spark.executor.memory\", \"8g\").getOrCreate()\n",
    "spark_session.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Elegimos el mes que vamos a analizar\n",
    "ruta_movements = r\"datos/movements/202012_movements.json\"\n",
    "ruta_stations = r\"datos/stations/202012_stations.json\"\n",
    "\n",
    "distancia = distancia_recorrida(ruta_movements, ruta_stations, spark_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de kilómetros realizados por los usuarios de BiciMad durante diciembre de 2020 son aproximadamente: 550924km\n"
     ]
    }
   ],
   "source": [
    "kilometros = int(distancia // 1000)\n",
    "print(f\"La cantidad de kilómetros realizados por los usuarios de BiciMad durante diciembre de 2020 son aproximadamente: {kilometros}km\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes datos son tomados de https://coches.idae.es/consumo-de-carburante-y-emisiones:\n",
    "\n",
    "* Por cada litro de gasolina consumido un coche emite un promedio de 2.35kg de CO2\n",
    "\n",
    "* Por cada litro de gasóleo consumido un coche emite un promedio de 2.64kg de CO2\n",
    "\n",
    "Habría que incluir otra serie de opciones pero estas dos son las principales\n",
    "\n",
    "Vamos a realizar un ejemplo de como calcular el CO2 que hemos reducido gracias a BiciMad\n",
    "\n",
    "Supongamos con el fin de simplificar el problema:\n",
    "1. Consumo medio 5 litro por 100km \n",
    "2. Porcentaje coches gasolina y gasoleo al 50%\n",
    "\n",
    "Crearemos un diccionario que incluye como clave el tipo de combustible y como valores una lista con consumo medio por 100km y porcentaje coches de ese combustible\n",
    "\n",
    "coches = {'Gasolina' : [litros_gasolina, porcentaje_gasolina, co2_litro_gasolina],'Gasóleo': [litros_gasoleo, porcentaje_gasoleo,co2_litro_gasóleo],...}\n",
    "\n",
    "Con nuestros supuestos:\n",
    "\n",
    "\n",
    "coches = {'Gasolina' : [5, 0.5, 2.34],'Gasóleo': [5, 0.5, 2.64]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracias BiciMad se han ahorrado aproximadamente unos 68590.038kg de CO2\n"
     ]
    }
   ],
   "source": [
    "resultado  = 0\n",
    "coches = {'Gasolina' : [5, 0.5, 2.34],'Gasóleo': [5, 0.5, 2.64]}\n",
    "co2 = sum([(((coches[i][1]*kilometros) / 100)*coches[i][0])*coches[i][2] for i in coches.keys()])\n",
    "\n",
    "print(f\"Gracias BiciMad se han ahorrado aproximadamente unos {co2}kg de CO2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión\n",
    "\n",
    "BiciMad desempeña un papel importante en la reducción de las emisiones de carbono y la promoción de la movilidad sostenible en las ciudades. Al fomentar el uso de la bicicleta como medio de transporte, se logra una disminución significativa de las emisiones de carbono y se mejora la calidad del aire. Además, se promueve un estilo de vida activo y saludable entre la población. La implementación y expansión de sistemas como BiciMad son fundamentales para avanzar hacia una movilidad más sostenible y contribuir a la mitigación del cambio climático."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1554ca09010399fa294997e9b93fe3492fe8acfeb68a288697aa104cf34db993"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
